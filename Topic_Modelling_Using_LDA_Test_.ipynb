{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Topic Modelling Using LDA Test .ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/revs1/Janatahack---AV-Hackathon-Topic-Modelling/blob/master/Topic_Modelling_Using_LDA_Test_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgduZIaBaS3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from sklearn import decomposition \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP7V_2eCbCX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f135329e-c03a-4851-f3ff-74d34446bc78"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi5Q1GZ5B-az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/sample_data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYyjGb_deCEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "2264bec3-5e13-4968-dc2e-d3eec2d0fba2"
      },
      "source": [
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20973</td>\n",
              "      <td>Closed-form Marginal Likelihood in Gamma-Poiss...</td>\n",
              "      <td>We present novel understandings of the Gamma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20974</td>\n",
              "      <td>Laboratory mid-IR spectra of equilibrated and ...</td>\n",
              "      <td>Meteorites contain minerals from Solar Syste...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20975</td>\n",
              "      <td>Case For Static AMSDU Aggregation in WLANs</td>\n",
              "      <td>Frame aggregation is a mechanism by which mu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20976</td>\n",
              "      <td>The $Gaia$-ESO Survey: the inner disk intermed...</td>\n",
              "      <td>Milky Way open clusters are very diverse in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20977</td>\n",
              "      <td>Witness-Functions versus Interpretation-Functi...</td>\n",
              "      <td>Proving that a cryptographic protocol is cor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8984</th>\n",
              "      <td>29957</td>\n",
              "      <td>Supporting mixed-datatype matrix multiplicatio...</td>\n",
              "      <td>We approach the problem of implementing mixe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8985</th>\n",
              "      <td>29958</td>\n",
              "      <td>An axiomatic basis for Blackwell optimality</td>\n",
              "      <td>In the theory of Markov decision processes (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8986</th>\n",
              "      <td>29959</td>\n",
              "      <td>GeneVis - An interactive visualization tool fo...</td>\n",
              "      <td>GeneVis is a web-based tool to visualize com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8987</th>\n",
              "      <td>29960</td>\n",
              "      <td>Quantifying the causal effect of speed cameras...</td>\n",
              "      <td>This paper quantifies the effect of speed ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8988</th>\n",
              "      <td>29961</td>\n",
              "      <td>Cube-magic labelings of grids</td>\n",
              "      <td>We show that the vertices and edges of a $d$...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8989 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID  ...                                           ABSTRACT\n",
              "0     20973  ...    We present novel understandings of the Gamma...\n",
              "1     20974  ...    Meteorites contain minerals from Solar Syste...\n",
              "2     20975  ...    Frame aggregation is a mechanism by which mu...\n",
              "3     20976  ...    Milky Way open clusters are very diverse in ...\n",
              "4     20977  ...    Proving that a cryptographic protocol is cor...\n",
              "...     ...  ...                                                ...\n",
              "8984  29957  ...    We approach the problem of implementing mixe...\n",
              "8985  29958  ...    In the theory of Markov decision processes (...\n",
              "8986  29959  ...    GeneVis is a web-based tool to visualize com...\n",
              "8987  29960  ...    This paper quantifies the effect of speed ca...\n",
              "8988  29961  ...    We show that the vertices and edges of a $d$...\n",
              "\n",
              "[8989 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct8Zb921kmYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2289f1a-22be-4e2a-b43e-e3edafc31f0f"
      },
      "source": [
        "pd.set_option('display.max_colwidth',-1)\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20973</td>\n",
              "      <td>Closed-form Marginal Likelihood in Gamma-Poisson Matrix Factorization</td>\n",
              "      <td>We present novel understandings of the Gamma-Poisson (GaP) model, a\\nprobabilistic matrix factorization model for count data. We show that GaP can\\nbe rewritten free of the score/activation matrix. This gives us new insights\\nabout the estimation of the topic/dictionary matrix by maximum marginal\\nlikelihood estimation. In particular, this explains the robustness of this\\nestimator to over-specified values of the factorization rank, especially its\\nability to automatically prune irrelevant dictionary columns, as empirically\\nobserved in previous work. The marginalization of the activation matrix leads\\nin turn to a new Monte Carlo Expectation-Maximization algorithm with favorable\\nproperties.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20974</td>\n",
              "      <td>Laboratory mid-IR spectra of equilibrated and igneous meteorites. Searching for observables of planetesimal debris</td>\n",
              "      <td>Meteorites contain minerals from Solar System asteroids with different\\nproperties (like size, presence of water, core formation). We provide new\\nmid-IR transmission spectra of powdered meteorites to obtain templates of how\\nmid-IR spectra of asteroidal debris would look like. This is essential for\\ninterpreting mid-IR spectra of past and future space observatories, like the\\nJames Webb Space Telescope. We show that the transmission spectra of wet and\\ndry chondrites, carbonaceous and ordinary chondrites and achondrite and\\nchondrite meteorites are distinctly different in a way one can distinguish in\\nastronomical mid-IR spectra. The two observables that spectroscopically\\nseparate the different meteorites groups (and thus the different types of\\nparent bodies) are the pyroxene-olivine feature strength ratio and the peak\\nshift of the olivine spectral features due to an increase in the iron\\nconcentration of the olivine.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20975</td>\n",
              "      <td>Case For Static AMSDU Aggregation in WLANs</td>\n",
              "      <td>Frame aggregation is a mechanism by which multiple frames are combined into a\\nsingle transmission unit over the air. Frames aggregated at the AMSDU level use\\na common CRC check to enforce integrity. For longer aggregated AMSDU frames,\\nthe packet error rate increases significantly for the same bit error rate.\\nHence, multiple studies have proposed doing AMSDU aggregation adaptively based\\non the error rate. This study evaluates if there is a \\emph{practical}\\nadvantage in doing adaptive AMSDU aggregation based on the link bit error rate.\\nEvaluations on a model show that instead of implementing a complex adaptive\\nAMSDU frame aggregation mechanism which impact queuing and other implementation\\naspects, it is easier to influence packet error rate with traditional\\nmechanisms while keeping the AMSDU aggregation logic simple.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20976</td>\n",
              "      <td>The $Gaia$-ESO Survey: the inner disk intermediate-age open cluster NGC 6802</td>\n",
              "      <td>Milky Way open clusters are very diverse in terms of age, chemical\\ncomposition, and kinematic properties. Intermediate-age and old open clusters\\nare less common, and it is even harder to find them inside the solar\\nGalactocentric radius, due to the high mortality rate and strong extinction\\ninside this region. NGC 6802 is one of the inner disk open clusters (IOCs)\\nobserved by the $Gaia$-ESO survey (GES). This cluster is an important target\\nfor calibrating the abundances derived in the survey due to the kinematic and\\nchemical homogeneity of the members in open clusters. Using the measurements\\nfrom $Gaia$-ESO internal data release 4 (iDR4), we identify 95 main-sequence\\ndwarfs as cluster members from the GIRAFFE target list, and eight giants as\\ncluster members from the UVES target list. The dwarf cluster members have a\\nmedian radial velocity of $13.6\\pm1.9$ km s$^{-1}$, while the giant cluster\\nmembers have a median radial velocity of $12.0\\pm0.9$ km s$^{-1}$ and a median\\n[Fe/H] of $0.10\\pm0.02$ dex. The color-magnitude diagram of these cluster\\nmembers suggests an age of $0.9\\pm0.1$ Gyr, with $(m-M)_0=11.4$ and\\n$E(B-V)=0.86$. We perform the first detailed chemical abundance analysis of NGC\\n6802, including 27 elemental species. To gain a more general picture about\\nIOCs, the measurements of NGC 6802 are compared with those of other IOCs\\npreviously studied by GES, that is, NGC 4815, Trumpler 20, NGC 6705, and\\nBerkeley 81. NGC 6802 shows similar C, N, Na, and Al abundances as other IOCs.\\nThese elements are compared with nucleosynthetic models as a function of\\ncluster turn-off mass. The $\\alpha$, iron-peak, and neutron-capture elements\\nare also explored in a self-consistent way.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20977</td>\n",
              "      <td>Witness-Functions versus Interpretation-Functions for Secrecy in Cryptographic Protocols: What to Choose?</td>\n",
              "      <td>Proving that a cryptographic protocol is correct for secrecy is a hard task.\\nOne of the strongest strategies to reach this goal is to show that it is\\nincreasing, which means that the security level of every single atomic message\\nexchanged in the protocol, safely evaluated, never deceases. Recently, two\\nfamilies of functions have been proposed to measure the security level of\\natomic messages. The first one is the family of interpretation-functions. The\\nsecond is the family of witness-functions. In this paper, we show that the\\nwitness-functions are more efficient than interpretation-functions. We give a\\ndetailed analysis of an ad-hoc protocol on which the witness-functions succeed\\nin proving its correctness for secrecy while the interpretation-functions fail\\nto do so.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8984</th>\n",
              "      <td>29957</td>\n",
              "      <td>Supporting mixed-datatype matrix multiplication within the BLIS framework</td>\n",
              "      <td>We approach the problem of implementing mixed-datatype support within the\\ngeneral matrix multiplication (GEMM) operation of the BLIS framework, whereby\\neach matrix operand A, B, and C may be stored as single- or double-precision\\nreal or complex values. Another factor of complexity, whereby the computation\\nis allowed to take place in a precision different from the storage precisions\\nof either A or B, is also included in the discussion. We first break the\\nproblem into mostly orthogonal dimensions, considering the mixing of domains\\nseparately from mixing precisions. Support for all combinations of matrix\\noperands stored in either the real or complex domain is mapped out by\\nenumerating the cases and describing an implementation approach for each.\\nSupporting all combinations of storage and computation precisions is handled by\\ntypecasting the matrices at key stages of the computation---during packing\\nand/or accumulation, as needed. Several optional optimizations are also\\ndocumented. Performance results gathered on a 56-core Marvell ThunderX2 and a\\n52-core Intel Xeon Platinum demonstrate that high performance is mostly\\npreserved, with modest slowdowns incurred from unavoidable typecast\\ninstructions. The mixed-datatype implementation confirms that combinatoric\\nintractability is avoided, with the framework relying on only two assembly\\nmicrokernels to implement 128 datatype combinations.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8985</th>\n",
              "      <td>29958</td>\n",
              "      <td>An axiomatic basis for Blackwell optimality</td>\n",
              "      <td>In the theory of Markov decision processes (MDPs), a Blackwell optimal policy\\nis a policy that is optimal for every discount factor sufficiently close to\\none. This paper provides an axiomatic basis for Blackwell optimality in\\ndiscrete-time MDPs with finitely many states and finitely many actions.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8986</th>\n",
              "      <td>29959</td>\n",
              "      <td>GeneVis - An interactive visualization tool for combining cross-discipline datasets within genetics</td>\n",
              "      <td>GeneVis is a web-based tool to visualize complementary data sets of different\\ndisciplines within the field of genetics. It overlays gene-cluster information,\\ngene-interaction data and gene-disease association data by means of web-based\\ninteractive graph visualizations. This allows an intuitive and quick assessment\\nof possible relations between the different datasets. By starting from a\\nhigh-level graph abstraction based on gene clusters, which can be selected for\\ndetailed inspection at the gene-interaction level in a separate window, GeneVis\\ncircumvents the common visual clutter problem when using gene datasets with a\\nhigh number of gene entries.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8987</th>\n",
              "      <td>29960</td>\n",
              "      <td>Quantifying the causal effect of speed cameras on road traffic accidents via an approximate Bayesian doubly robust estimator</td>\n",
              "      <td>This paper quantifies the effect of speed cameras on road traffic collisions\\nusing an approximate Bayesian doubly-robust (DR) causal inference estimation\\nmethod. Previous empirical work on this topic, which shows a diverse range of\\nestimated effects, is based largely on outcome regression (OR) models using the\\nEmpirical Bayes approach or on simple before and after comparisons. Issues of\\ncausality and confounding have received little formal attention. A causal DR\\napproach combines propensity score (PS) and OR models to give an average\\ntreatment effect (ATE) estimator that is consistent and asymptotically normal\\nunder correct specification of either of the two component models. We develop\\nthis approach within a novel approximate Bayesian framework to derive posterior\\npredictive distributions for the ATE of speed cameras on road traffic\\ncollisions. Our results for England indicate significant reductions in the\\nnumber of collisions at speed cameras sites (mean ATE = -30%). Our proposed\\nmethod offers a promising approach for evaluation of transport safety\\ninterventions.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8988</th>\n",
              "      <td>29961</td>\n",
              "      <td>Cube-magic labelings of grids</td>\n",
              "      <td>We show that the vertices and edges of a $d$-dimensional grid graph $G=(V,E)$\\n($d\\geqslant 2$) can be labeled with the integers from $\\{1,\\ldots,\\lvert\\nV\\rvert\\}$ and $\\{1,\\ldots,\\lvert E\\rvert\\}$, respectively, in such a way that\\nfor every subgraph $H$ isomorphic to a $d$-cube the sum of all the labels of\\n$H$ is the same. As a consequence, for every $d\\geqslant 2$, every\\n$d$-dimensional grid graph is $Q_d$-supermagic where $Q_d$ is the $d$-cube.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8989 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ABSTRACT\n",
              "0     20973  ...    We present novel understandings of the Gamma-Poisson (GaP) model, a\\nprobabilistic matrix factorization model for count data. We show that GaP can\\nbe rewritten free of the score/activation matrix. This gives us new insights\\nabout the estimation of the topic/dictionary matrix by maximum marginal\\nlikelihood estimation. In particular, this explains the robustness of this\\nestimator to over-specified values of the factorization rank, especially its\\nability to automatically prune irrelevant dictionary columns, as empirically\\nobserved in previous work. The marginalization of the activation matrix leads\\nin turn to a new Monte Carlo Expectation-Maximization algorithm with favorable\\nproperties.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
              "1     20974  ...    Meteorites contain minerals from Solar System asteroids with different\\nproperties (like size, presence of water, core formation). We provide new\\nmid-IR transmission spectra of powdered meteorites to obtain templates of how\\nmid-IR spectra of asteroidal debris would look like. This is essential for\\ninterpreting mid-IR spectra of past and future space observatories, like the\\nJames Webb Space Telescope. We show that the transmission spectra of wet and\\ndry chondrites, carbonaceous and ordinary chondrites and achondrite and\\nchondrite meteorites are distinctly different in a way one can distinguish in\\nastronomical mid-IR spectra. The two observables that spectroscopically\\nseparate the different meteorites groups (and thus the different types of\\nparent bodies) are the pyroxene-olivine feature strength ratio and the peak\\nshift of the olivine spectral features due to an increase in the iron\\nconcentration of the olivine.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "2     20975  ...    Frame aggregation is a mechanism by which multiple frames are combined into a\\nsingle transmission unit over the air. Frames aggregated at the AMSDU level use\\na common CRC check to enforce integrity. For longer aggregated AMSDU frames,\\nthe packet error rate increases significantly for the same bit error rate.\\nHence, multiple studies have proposed doing AMSDU aggregation adaptively based\\non the error rate. This study evaluates if there is a \\emph{practical}\\nadvantage in doing adaptive AMSDU aggregation based on the link bit error rate.\\nEvaluations on a model show that instead of implementing a complex adaptive\\nAMSDU frame aggregation mechanism which impact queuing and other implementation\\naspects, it is easier to influence packet error rate with traditional\\nmechanisms while keeping the AMSDU aggregation logic simple.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
              "3     20976  ...    Milky Way open clusters are very diverse in terms of age, chemical\\ncomposition, and kinematic properties. Intermediate-age and old open clusters\\nare less common, and it is even harder to find them inside the solar\\nGalactocentric radius, due to the high mortality rate and strong extinction\\ninside this region. NGC 6802 is one of the inner disk open clusters (IOCs)\\nobserved by the $Gaia$-ESO survey (GES). This cluster is an important target\\nfor calibrating the abundances derived in the survey due to the kinematic and\\nchemical homogeneity of the members in open clusters. Using the measurements\\nfrom $Gaia$-ESO internal data release 4 (iDR4), we identify 95 main-sequence\\ndwarfs as cluster members from the GIRAFFE target list, and eight giants as\\ncluster members from the UVES target list. The dwarf cluster members have a\\nmedian radial velocity of $13.6\\pm1.9$ km s$^{-1}$, while the giant cluster\\nmembers have a median radial velocity of $12.0\\pm0.9$ km s$^{-1}$ and a median\\n[Fe/H] of $0.10\\pm0.02$ dex. The color-magnitude diagram of these cluster\\nmembers suggests an age of $0.9\\pm0.1$ Gyr, with $(m-M)_0=11.4$ and\\n$E(B-V)=0.86$. We perform the first detailed chemical abundance analysis of NGC\\n6802, including 27 elemental species. To gain a more general picture about\\nIOCs, the measurements of NGC 6802 are compared with those of other IOCs\\npreviously studied by GES, that is, NGC 4815, Trumpler 20, NGC 6705, and\\nBerkeley 81. NGC 6802 shows similar C, N, Na, and Al abundances as other IOCs.\\nThese elements are compared with nucleosynthetic models as a function of\\ncluster turn-off mass. The $\\alpha$, iron-peak, and neutron-capture elements\\nare also explored in a self-consistent way.\\n\n",
              "4     20977  ...    Proving that a cryptographic protocol is correct for secrecy is a hard task.\\nOne of the strongest strategies to reach this goal is to show that it is\\nincreasing, which means that the security level of every single atomic message\\nexchanged in the protocol, safely evaluated, never deceases. Recently, two\\nfamilies of functions have been proposed to measure the security level of\\natomic messages. The first one is the family of interpretation-functions. The\\nsecond is the family of witness-functions. In this paper, we show that the\\nwitness-functions are more efficient than interpretation-functions. We give a\\ndetailed analysis of an ad-hoc protocol on which the witness-functions succeed\\nin proving its correctness for secrecy while the interpretation-functions fail\\nto do so.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "...     ...  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "8984  29957  ...    We approach the problem of implementing mixed-datatype support within the\\ngeneral matrix multiplication (GEMM) operation of the BLIS framework, whereby\\neach matrix operand A, B, and C may be stored as single- or double-precision\\nreal or complex values. Another factor of complexity, whereby the computation\\nis allowed to take place in a precision different from the storage precisions\\nof either A or B, is also included in the discussion. We first break the\\nproblem into mostly orthogonal dimensions, considering the mixing of domains\\nseparately from mixing precisions. Support for all combinations of matrix\\noperands stored in either the real or complex domain is mapped out by\\nenumerating the cases and describing an implementation approach for each.\\nSupporting all combinations of storage and computation precisions is handled by\\ntypecasting the matrices at key stages of the computation---during packing\\nand/or accumulation, as needed. Several optional optimizations are also\\ndocumented. Performance results gathered on a 56-core Marvell ThunderX2 and a\\n52-core Intel Xeon Platinum demonstrate that high performance is mostly\\npreserved, with modest slowdowns incurred from unavoidable typecast\\ninstructions. The mixed-datatype implementation confirms that combinatoric\\nintractability is avoided, with the framework relying on only two assembly\\nmicrokernels to implement 128 datatype combinations.\\n                                                                                                                                                                                                                                                                                                            \n",
              "8985  29958  ...    In the theory of Markov decision processes (MDPs), a Blackwell optimal policy\\nis a policy that is optimal for every discount factor sufficiently close to\\none. This paper provides an axiomatic basis for Blackwell optimality in\\ndiscrete-time MDPs with finitely many states and finitely many actions.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
              "8986  29959  ...    GeneVis is a web-based tool to visualize complementary data sets of different\\ndisciplines within the field of genetics. It overlays gene-cluster information,\\ngene-interaction data and gene-disease association data by means of web-based\\ninteractive graph visualizations. This allows an intuitive and quick assessment\\nof possible relations between the different datasets. By starting from a\\nhigh-level graph abstraction based on gene clusters, which can be selected for\\ndetailed inspection at the gene-interaction level in a separate window, GeneVis\\ncircumvents the common visual clutter problem when using gene datasets with a\\nhigh number of gene entries.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
              "8987  29960  ...    This paper quantifies the effect of speed cameras on road traffic collisions\\nusing an approximate Bayesian doubly-robust (DR) causal inference estimation\\nmethod. Previous empirical work on this topic, which shows a diverse range of\\nestimated effects, is based largely on outcome regression (OR) models using the\\nEmpirical Bayes approach or on simple before and after comparisons. Issues of\\ncausality and confounding have received little formal attention. A causal DR\\napproach combines propensity score (PS) and OR models to give an average\\ntreatment effect (ATE) estimator that is consistent and asymptotically normal\\nunder correct specification of either of the two component models. We develop\\nthis approach within a novel approximate Bayesian framework to derive posterior\\npredictive distributions for the ATE of speed cameras on road traffic\\ncollisions. Our results for England indicate significant reductions in the\\nnumber of collisions at speed cameras sites (mean ATE = -30%). Our proposed\\nmethod offers a promising approach for evaluation of transport safety\\ninterventions.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "8988  29961  ...    We show that the vertices and edges of a $d$-dimensional grid graph $G=(V,E)$\\n($d\\geqslant 2$) can be labeled with the integers from $\\{1,\\ldots,\\lvert\\nV\\rvert\\}$ and $\\{1,\\ldots,\\lvert E\\rvert\\}$, respectively, in such a way that\\nfor every subgraph $H$ isomorphic to a $d$-cube the sum of all the labels of\\n$H$ is the same. As a consequence, for every $d\\geqslant 2$, every\\n$d$-dimensional grid graph is $Q_d$-supermagic where $Q_d$ is the $d$-cube.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "\n",
              "[8989 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZpcdhX4lHPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "X_train = df.copy()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBhlD-jblXWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "  tokens = [word for word in nltk.word_tokenize(text) if (len(word)>3 and len(word.strip('Xx/'))>2)]\n",
        "  #stems = [stemmer.stem(item) for item in tokens]\n",
        "  return tokens"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGkZ-5EQO_JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "newStopWords =  ['s','t',  'm', 're','don','ve','2', '3', '1', \n",
        "                 'it', 'i', 'us', 'get', 'you', 'let', 'going', 'know', \n",
        "                'make', 'take', 'still','got', 'can', 'this', 'all', 'me','go',\n",
        "                'even', 'here', 'well', 'much', 'many', 'way', 'want', 'every', 'little',\n",
        "                 '']\n",
        "stopwords.extend(newStopWords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqMOqPaymnPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer_tf = TfidfVectorizer(tokenizer= tokenize,stop_words='english',max_df=0.75,min_df=50,max_features=10000,use_idf=False,norm=None)\n",
        "tf_vectors = vectorizer_tf.fit_transform(X_train.ABSTRACT)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBNUdtGWnXgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "06057666-4f61-46c1-e674-bed9b6d3b2f4"
      },
      "source": [
        "tf_vectors.A"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [2., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E0PRVkCoRQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63e581fe-5491-4539-e5f6-ae588a482d2f"
      },
      "source": [
        "vectorizer_tf.get_feature_names()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['-dimensional',\n",
              " '2015',\n",
              " '2016',\n",
              " '2017',\n",
              " '\\\\alpha',\n",
              " '\\\\beta',\n",
              " '\\\\cite',\n",
              " '\\\\delta',\n",
              " '\\\\emph',\n",
              " '\\\\epsilon',\n",
              " '\\\\frac',\n",
              " '\\\\gamma',\n",
              " '\\\\geq',\n",
              " '\\\\infty',\n",
              " '\\\\lambda',\n",
              " '\\\\leq',\n",
              " '\\\\log',\n",
              " '\\\\mathbb',\n",
              " '\\\\mathbf',\n",
              " '\\\\mathcal',\n",
              " '\\\\mathrm',\n",
              " '\\\\omega',\n",
              " '\\\\right',\n",
              " '\\\\sigma',\n",
              " '\\\\sim',\n",
              " '\\\\sqrt',\n",
              " '\\\\textit',\n",
              " '\\\\times',\n",
              " 'abelian',\n",
              " 'ability',\n",
              " 'able',\n",
              " 'absence',\n",
              " 'absolute',\n",
              " 'absorption',\n",
              " 'abstract',\n",
              " 'abundance',\n",
              " 'acceleration',\n",
              " 'access',\n",
              " 'according',\n",
              " 'account',\n",
              " 'accuracy',\n",
              " 'accurate',\n",
              " 'accurately',\n",
              " 'achieve',\n",
              " 'achieved',\n",
              " 'achieves',\n",
              " 'achieving',\n",
              " 'acoustic',\n",
              " 'acquired',\n",
              " 'acquisition',\n",
              " 'action',\n",
              " 'actions',\n",
              " 'activation',\n",
              " 'active',\n",
              " 'activities',\n",
              " 'activity',\n",
              " 'actual',\n",
              " 'actually',\n",
              " 'adapt',\n",
              " 'adaptation',\n",
              " 'adapted',\n",
              " 'adaptive',\n",
              " 'added',\n",
              " 'adding',\n",
              " 'addition',\n",
              " 'additional',\n",
              " 'additionally',\n",
              " 'additive',\n",
              " 'address',\n",
              " 'addressed',\n",
              " 'addresses',\n",
              " 'admits',\n",
              " 'adopt',\n",
              " 'adopted',\n",
              " 'advanced',\n",
              " 'advances',\n",
              " 'advantage',\n",
              " 'advantages',\n",
              " 'adversarial',\n",
              " 'affect',\n",
              " 'affected',\n",
              " 'affects',\n",
              " 'affine',\n",
              " 'agent',\n",
              " 'agents',\n",
              " 'agreement',\n",
              " 'aims',\n",
              " 'algebra',\n",
              " 'algebraic',\n",
              " 'algebras',\n",
              " 'algorithm',\n",
              " 'algorithmic',\n",
              " 'algorithms',\n",
              " 'alignment',\n",
              " 'allocation',\n",
              " 'allow',\n",
              " 'allowed',\n",
              " 'allowing',\n",
              " 'allows',\n",
              " 'alternating',\n",
              " 'alternative',\n",
              " 'amounts',\n",
              " 'amplitude',\n",
              " 'analogue',\n",
              " 'analyse',\n",
              " 'analyses',\n",
              " 'analysis',\n",
              " 'analytic',\n",
              " 'analytical',\n",
              " 'analytically',\n",
              " 'analyze',\n",
              " 'analyzed',\n",
              " 'analyzing',\n",
              " 'and/or',\n",
              " 'angle',\n",
              " 'angular',\n",
              " 'anisotropic',\n",
              " 'anisotropy',\n",
              " 'anomalous',\n",
              " 'answer',\n",
              " 'antiferromagnetic',\n",
              " 'appear',\n",
              " 'appears',\n",
              " 'applicability',\n",
              " 'applicable',\n",
              " 'application',\n",
              " 'applications',\n",
              " 'applied',\n",
              " 'applies',\n",
              " 'apply',\n",
              " 'applying',\n",
              " 'approach',\n",
              " 'approaches',\n",
              " 'appropriate',\n",
              " 'approximate',\n",
              " 'approximated',\n",
              " 'approximately',\n",
              " 'approximating',\n",
              " 'approximation',\n",
              " 'approximations',\n",
              " 'arbitrarily',\n",
              " 'arbitrary',\n",
              " 'architecture',\n",
              " 'architectures',\n",
              " 'area',\n",
              " 'areas',\n",
              " 'argue',\n",
              " 'arguments',\n",
              " 'arise',\n",
              " 'arises',\n",
              " 'arising',\n",
              " 'array',\n",
              " 'article',\n",
              " 'artificial',\n",
              " 'aspects',\n",
              " 'assess',\n",
              " 'assessment',\n",
              " 'associated',\n",
              " 'association',\n",
              " 'assume',\n",
              " 'assumed',\n",
              " 'assuming',\n",
              " 'assumption',\n",
              " 'assumptions',\n",
              " 'asymptotic',\n",
              " 'asymptotically',\n",
              " 'atomic',\n",
              " 'atoms',\n",
              " 'attack',\n",
              " 'attacks',\n",
              " 'attempt',\n",
              " 'attempts',\n",
              " 'attention',\n",
              " 'attractive',\n",
              " 'attributed',\n",
              " 'attributes',\n",
              " 'audio',\n",
              " 'author',\n",
              " 'authors',\n",
              " 'automated',\n",
              " 'automatic',\n",
              " 'automatically',\n",
              " 'autonomous',\n",
              " 'auxiliary',\n",
              " 'availability',\n",
              " 'available',\n",
              " 'average',\n",
              " 'avoid',\n",
              " 'away',\n",
              " 'axis',\n",
              " 'background',\n",
              " 'balance',\n",
              " 'band',\n",
              " 'bands',\n",
              " 'bandwidth',\n",
              " 'base',\n",
              " 'based',\n",
              " 'baseline',\n",
              " 'baselines',\n",
              " 'basic',\n",
              " 'basis',\n",
              " 'bayesian',\n",
              " 'beam',\n",
              " 'behavior',\n",
              " 'behaviors',\n",
              " 'behaviour',\n",
              " 'believe',\n",
              " 'benchmark',\n",
              " 'benchmarks',\n",
              " 'benefit',\n",
              " 'benefits',\n",
              " 'best',\n",
              " 'better',\n",
              " 'bias',\n",
              " 'binary',\n",
              " 'biological',\n",
              " 'black',\n",
              " 'block',\n",
              " 'blocks',\n",
              " 'body',\n",
              " 'bound',\n",
              " 'boundaries',\n",
              " 'boundary',\n",
              " 'bounded',\n",
              " 'bounds',\n",
              " 'brain',\n",
              " 'breaking',\n",
              " 'bridge',\n",
              " 'briefly',\n",
              " 'broad',\n",
              " 'build',\n",
              " 'building',\n",
              " 'built',\n",
              " 'bulk',\n",
              " 'bundle',\n",
              " 'calculate',\n",
              " 'calculated',\n",
              " 'calculation',\n",
              " 'calculations',\n",
              " 'calibration',\n",
              " 'called',\n",
              " 'camera',\n",
              " 'candidate',\n",
              " 'candidates',\n",
              " 'canonical',\n",
              " 'capabilities',\n",
              " 'capability',\n",
              " 'capable',\n",
              " 'capacity',\n",
              " 'capture',\n",
              " 'captured',\n",
              " 'captures',\n",
              " 'carlo',\n",
              " 'carried',\n",
              " 'carry',\n",
              " 'case',\n",
              " 'cases',\n",
              " 'categories',\n",
              " 'category',\n",
              " 'causal',\n",
              " 'cause',\n",
              " 'caused',\n",
              " 'causes',\n",
              " 'cell',\n",
              " 'cells',\n",
              " 'cellular',\n",
              " 'center',\n",
              " 'central',\n",
              " 'certain',\n",
              " 'chain',\n",
              " 'chains',\n",
              " 'challenge',\n",
              " 'challenges',\n",
              " 'challenging',\n",
              " 'change',\n",
              " 'changes',\n",
              " 'changing',\n",
              " 'channel',\n",
              " 'channels',\n",
              " 'character',\n",
              " 'characteristic',\n",
              " 'characteristics',\n",
              " 'characterization',\n",
              " 'characterize',\n",
              " 'characterized',\n",
              " 'characterizing',\n",
              " 'charge',\n",
              " 'chemical',\n",
              " 'choice',\n",
              " 'choices',\n",
              " 'choose',\n",
              " 'choosing',\n",
              " 'chosen',\n",
              " 'circuits',\n",
              " 'class',\n",
              " 'classes',\n",
              " 'classic',\n",
              " 'classical',\n",
              " 'classification',\n",
              " 'classifier',\n",
              " 'classifiers',\n",
              " 'classify',\n",
              " 'clear',\n",
              " 'clearly',\n",
              " 'clinical',\n",
              " 'close',\n",
              " 'closed',\n",
              " 'closely',\n",
              " 'cloud',\n",
              " 'cluster',\n",
              " 'clustering',\n",
              " 'clusters',\n",
              " 'code',\n",
              " 'codes',\n",
              " 'coefficient',\n",
              " 'coefficients',\n",
              " 'cognitive',\n",
              " 'coherent',\n",
              " 'cohomology',\n",
              " 'cold',\n",
              " 'collect',\n",
              " 'collected',\n",
              " 'collection',\n",
              " 'collective',\n",
              " 'combination',\n",
              " 'combinations',\n",
              " 'combinatorial',\n",
              " 'combine',\n",
              " 'combined',\n",
              " 'combines',\n",
              " 'combining',\n",
              " 'come',\n",
              " 'comes',\n",
              " 'common',\n",
              " 'commonly',\n",
              " 'communication',\n",
              " 'communications',\n",
              " 'communities',\n",
              " 'community',\n",
              " 'compact',\n",
              " 'comparable',\n",
              " 'compare',\n",
              " 'compared',\n",
              " 'comparing',\n",
              " 'comparison',\n",
              " 'comparisons',\n",
              " 'compatible',\n",
              " 'competing',\n",
              " 'competition',\n",
              " 'competitive',\n",
              " 'complement',\n",
              " 'complementary',\n",
              " 'complete',\n",
              " 'completely',\n",
              " 'complex',\n",
              " 'complexity',\n",
              " 'complicated',\n",
              " 'component',\n",
              " 'components',\n",
              " 'composed',\n",
              " 'composition',\n",
              " 'compound',\n",
              " 'comprehensive',\n",
              " 'compression',\n",
              " 'computation',\n",
              " 'computational',\n",
              " 'computationally',\n",
              " 'computations',\n",
              " 'compute',\n",
              " 'computed',\n",
              " 'computer',\n",
              " 'computing',\n",
              " 'concentration',\n",
              " 'concept',\n",
              " 'concepts',\n",
              " 'concerning',\n",
              " 'concerns',\n",
              " 'conclude',\n",
              " 'conclusion',\n",
              " 'conclusions',\n",
              " 'condition',\n",
              " 'conditional',\n",
              " 'conditions',\n",
              " 'conduct',\n",
              " 'conducted',\n",
              " 'confidence',\n",
              " 'configuration',\n",
              " 'configurations',\n",
              " 'confirm',\n",
              " 'confirmed',\n",
              " 'conjecture',\n",
              " 'connected',\n",
              " 'connection',\n",
              " 'connections',\n",
              " 'connectivity',\n",
              " 'consequence',\n",
              " 'consequences',\n",
              " 'consequently',\n",
              " 'consider',\n",
              " 'considerable',\n",
              " 'considerably',\n",
              " 'consideration',\n",
              " 'considered',\n",
              " 'considering',\n",
              " 'considers',\n",
              " 'consistency',\n",
              " 'consistent',\n",
              " 'consistently',\n",
              " 'consisting',\n",
              " 'consists',\n",
              " 'constant',\n",
              " 'constants',\n",
              " 'constrain',\n",
              " 'constrained',\n",
              " 'constraint',\n",
              " 'constraints',\n",
              " 'construct',\n",
              " 'constructed',\n",
              " 'constructing',\n",
              " 'construction',\n",
              " 'consumption',\n",
              " 'contact',\n",
              " 'contain',\n",
              " 'containing',\n",
              " 'contains',\n",
              " 'content',\n",
              " 'context',\n",
              " 'continuous',\n",
              " 'continuously',\n",
              " 'continuum',\n",
              " 'contrast',\n",
              " 'contribute',\n",
              " 'contribution',\n",
              " 'contributions',\n",
              " 'control',\n",
              " 'controlled',\n",
              " 'controller',\n",
              " 'conventional',\n",
              " 'converge',\n",
              " 'convergence',\n",
              " 'converges',\n",
              " 'convex',\n",
              " 'convolutional',\n",
              " 'coordinate',\n",
              " 'coordinates',\n",
              " 'core',\n",
              " 'corpus',\n",
              " 'correct',\n",
              " 'correction',\n",
              " 'correctly',\n",
              " 'correlated',\n",
              " 'correlation',\n",
              " 'correlations',\n",
              " 'correspond',\n",
              " 'correspondence',\n",
              " 'corresponding',\n",
              " 'corresponds',\n",
              " 'cosmic',\n",
              " 'cosmological',\n",
              " 'cost',\n",
              " 'costs',\n",
              " 'count',\n",
              " 'counterpart',\n",
              " 'coupled',\n",
              " 'coupling',\n",
              " 'course',\n",
              " 'covariance',\n",
              " 'cover',\n",
              " 'coverage',\n",
              " 'covering',\n",
              " 'create',\n",
              " 'created',\n",
              " 'creating',\n",
              " 'criteria',\n",
              " 'criterion',\n",
              " 'critical',\n",
              " 'cross',\n",
              " 'crucial',\n",
              " 'crystal',\n",
              " 'current',\n",
              " 'currently',\n",
              " 'curvature',\n",
              " 'curve',\n",
              " 'curves',\n",
              " 'cycle',\n",
              " 'cycles',\n",
              " 'dark',\n",
              " 'data',\n",
              " 'data-driven',\n",
              " 'database',\n",
              " 'dataset',\n",
              " 'datasets',\n",
              " 'days',\n",
              " 'deal',\n",
              " 'dealing',\n",
              " 'decades',\n",
              " 'decay',\n",
              " 'decision',\n",
              " 'decisions',\n",
              " 'decomposition',\n",
              " 'decrease',\n",
              " 'decreases',\n",
              " 'decreasing',\n",
              " 'deep',\n",
              " 'define',\n",
              " 'defined',\n",
              " 'defining',\n",
              " 'definition',\n",
              " 'deformation',\n",
              " 'degenerate',\n",
              " 'degree',\n",
              " 'degrees',\n",
              " 'delay',\n",
              " 'demand',\n",
              " 'demonstrate',\n",
              " 'demonstrated',\n",
              " 'demonstrates',\n",
              " 'demonstrating',\n",
              " 'dense',\n",
              " 'densities',\n",
              " 'density',\n",
              " 'depend',\n",
              " 'dependence',\n",
              " 'dependencies',\n",
              " 'dependency',\n",
              " 'dependent',\n",
              " 'depending',\n",
              " 'depends',\n",
              " 'deployed',\n",
              " 'depth',\n",
              " 'derivative',\n",
              " 'derivatives',\n",
              " 'derive',\n",
              " 'derived',\n",
              " 'descent',\n",
              " 'described',\n",
              " 'describes',\n",
              " 'describing',\n",
              " 'description',\n",
              " 'design',\n",
              " 'designed',\n",
              " 'designing',\n",
              " 'designs',\n",
              " 'desirable',\n",
              " 'desired',\n",
              " 'despite',\n",
              " 'detailed',\n",
              " 'details',\n",
              " 'detect',\n",
              " 'detected',\n",
              " 'detecting',\n",
              " 'detection',\n",
              " 'detector',\n",
              " 'determination',\n",
              " 'determine',\n",
              " 'determined',\n",
              " 'determines',\n",
              " 'determining',\n",
              " 'deterministic',\n",
              " 'develop',\n",
              " 'developed',\n",
              " 'developing',\n",
              " 'development',\n",
              " 'deviation',\n",
              " 'device',\n",
              " 'devices',\n",
              " 'diagram',\n",
              " 'differ',\n",
              " 'difference',\n",
              " 'differences',\n",
              " 'different',\n",
              " 'differential',\n",
              " 'difficult',\n",
              " 'difficulty',\n",
              " 'diffusion',\n",
              " 'digital',\n",
              " 'dimension',\n",
              " 'dimensional',\n",
              " 'dimensionality',\n",
              " 'dimensions',\n",
              " 'direct',\n",
              " 'directed',\n",
              " 'direction',\n",
              " 'directions',\n",
              " 'directly',\n",
              " 'discover',\n",
              " 'discovered',\n",
              " 'discovery',\n",
              " 'discrete',\n",
              " 'discuss',\n",
              " 'discussed',\n",
              " 'discussion',\n",
              " 'disease',\n",
              " 'disk',\n",
              " 'disorder',\n",
              " 'dispersion',\n",
              " 'distance',\n",
              " 'distances',\n",
              " 'distinct',\n",
              " 'distinguish',\n",
              " 'distributed',\n",
              " 'distribution',\n",
              " 'distributions',\n",
              " 'divergence',\n",
              " 'diverse',\n",
              " 'diversity',\n",
              " 'document',\n",
              " 'does',\n",
              " 'domain',\n",
              " 'domains',\n",
              " 'dominant',\n",
              " 'dominated',\n",
              " 'double',\n",
              " 'dramatically',\n",
              " 'drawn',\n",
              " 'drive',\n",
              " 'driven',\n",
              " 'driving',\n",
              " 'dual',\n",
              " 'duality',\n",
              " 'dust',\n",
              " 'dynamic',\n",
              " 'dynamical',\n",
              " 'dynamically',\n",
              " 'dynamics',\n",
              " 'e.g.',\n",
              " 'earlier',\n",
              " 'early',\n",
              " 'earth',\n",
              " 'easily',\n",
              " 'easy',\n",
              " 'economic',\n",
              " 'edge',\n",
              " 'edges',\n",
              " 'effect',\n",
              " 'effective',\n",
              " 'effectively',\n",
              " 'effectiveness',\n",
              " 'effects',\n",
              " 'efficacy',\n",
              " 'efficiency',\n",
              " 'efficient',\n",
              " 'efficiently',\n",
              " 'effort',\n",
              " 'efforts',\n",
              " 'eigenvalue',\n",
              " 'eigenvalues',\n",
              " 'elastic',\n",
              " 'electric',\n",
              " 'electrical',\n",
              " 'electromagnetic',\n",
              " 'electron',\n",
              " 'electronic',\n",
              " 'electrons',\n",
              " 'element',\n",
              " 'elementary',\n",
              " 'elements',\n",
              " 'elliptic',\n",
              " 'embedded',\n",
              " 'embedding',\n",
              " 'embeddings',\n",
              " 'emergence',\n",
              " 'emerging',\n",
              " 'emission',\n",
              " 'empirical',\n",
              " 'empirically',\n",
              " 'employ',\n",
              " 'employed',\n",
              " 'employing',\n",
              " 'employs',\n",
              " 'enable',\n",
              " 'enables',\n",
              " 'enabling',\n",
              " 'encoding',\n",
              " 'end-to-end',\n",
              " 'energies',\n",
              " 'energy',\n",
              " 'engineering',\n",
              " 'enhance',\n",
              " 'enhanced',\n",
              " 'enhancement',\n",
              " 'ensemble',\n",
              " 'ensure',\n",
              " 'entire',\n",
              " 'entirely',\n",
              " 'entities',\n",
              " 'entropy',\n",
              " 'environment',\n",
              " 'environmental',\n",
              " 'environments',\n",
              " 'equal',\n",
              " 'equation',\n",
              " 'equations',\n",
              " 'equilibrium',\n",
              " 'equipped',\n",
              " 'equivalence',\n",
              " 'equivalent',\n",
              " 'error',\n",
              " 'errors',\n",
              " 'especially',\n",
              " 'essential',\n",
              " 'essentially',\n",
              " 'establish',\n",
              " 'established',\n",
              " 'estimate',\n",
              " 'estimated',\n",
              " 'estimates',\n",
              " 'estimating',\n",
              " 'estimation',\n",
              " 'estimator',\n",
              " 'estimators',\n",
              " 'euclidean',\n",
              " 'euler',\n",
              " 'evaluate',\n",
              " 'evaluated',\n",
              " 'evaluating',\n",
              " 'evaluation',\n",
              " 'evaluations',\n",
              " 'event',\n",
              " 'events',\n",
              " 'eventually',\n",
              " 'evidence',\n",
              " 'evolution',\n",
              " 'evolutionary',\n",
              " 'evolving',\n",
              " 'exact',\n",
              " 'exactly',\n",
              " 'examine',\n",
              " 'examined',\n",
              " 'example',\n",
              " 'examples',\n",
              " 'excellent',\n",
              " 'exchange',\n",
              " 'excitation',\n",
              " 'excitations',\n",
              " 'execution',\n",
              " 'exhibit',\n",
              " 'exhibits',\n",
              " 'exist',\n",
              " 'existence',\n",
              " 'existing',\n",
              " 'exists',\n",
              " 'expansion',\n",
              " 'expectation',\n",
              " 'expected',\n",
              " 'expensive',\n",
              " 'experience',\n",
              " 'experiment',\n",
              " 'experimental',\n",
              " 'experimentally',\n",
              " 'experiments',\n",
              " 'experts',\n",
              " 'explain',\n",
              " 'explained',\n",
              " 'explicit',\n",
              " 'explicitly',\n",
              " 'exploit',\n",
              " 'exploited',\n",
              " 'exploiting',\n",
              " 'exploits',\n",
              " 'exploration',\n",
              " 'explore',\n",
              " 'explored',\n",
              " 'exploring',\n",
              " 'exponent',\n",
              " 'exponential',\n",
              " 'exponentially',\n",
              " 'expressed',\n",
              " 'expression',\n",
              " 'expressions',\n",
              " 'extend',\n",
              " 'extended',\n",
              " 'extending',\n",
              " 'extends',\n",
              " 'extension',\n",
              " 'extensions',\n",
              " 'extensive',\n",
              " 'extensively',\n",
              " 'extent',\n",
              " 'external',\n",
              " 'extra',\n",
              " 'extract',\n",
              " 'extracted',\n",
              " 'extracting',\n",
              " 'extraction',\n",
              " 'extreme',\n",
              " 'extremely',\n",
              " 'face',\n",
              " 'facilitate',\n",
              " 'fact',\n",
              " 'factor',\n",
              " 'factorization',\n",
              " 'factors',\n",
              " 'fail',\n",
              " 'failure',\n",
              " 'false',\n",
              " 'families',\n",
              " 'family',\n",
              " 'fashion',\n",
              " 'fast',\n",
              " 'faster',\n",
              " 'feasibility',\n",
              " 'feasible',\n",
              " 'feature',\n",
              " 'features',\n",
              " 'feedback',\n",
              " 'fermi',\n",
              " 'field',\n",
              " 'fields',\n",
              " 'films',\n",
              " 'filter',\n",
              " 'filtering',\n",
              " 'final',\n",
              " 'finally',\n",
              " 'financial',\n",
              " 'finding',\n",
              " 'findings',\n",
              " 'finds',\n",
              " 'fine',\n",
              " 'finite',\n",
              " 'first-order',\n",
              " 'firstly',\n",
              " 'fitting',\n",
              " 'fixed',\n",
              " 'flat',\n",
              " 'flexibility',\n",
              " 'flexible',\n",
              " 'flow',\n",
              " 'flows',\n",
              " 'fluctuations',\n",
              " 'fluid',\n",
              " 'flux',\n",
              " 'focus',\n",
              " 'focused',\n",
              " 'focuses',\n",
              " 'focusing',\n",
              " 'follow',\n",
              " 'followed',\n",
              " 'following',\n",
              " 'follows',\n",
              " 'force',\n",
              " 'forces',\n",
              " 'form',\n",
              " 'formal',\n",
              " 'formalism',\n",
              " 'formation',\n",
              " 'formed',\n",
              " 'forming',\n",
              " 'forms',\n",
              " 'formula',\n",
              " 'formulas',\n",
              " 'formulate',\n",
              " 'formulated',\n",
              " 'formulation',\n",
              " 'forward',\n",
              " 'fourier',\n",
              " 'fraction',\n",
              " 'fractional',\n",
              " 'frame',\n",
              " 'frames',\n",
              " 'framework',\n",
              " 'frameworks',\n",
              " 'free',\n",
              " 'freedom',\n",
              " 'frequencies',\n",
              " 'frequency',\n",
              " 'fully',\n",
              " 'function',\n",
              " 'functional',\n",
              " 'functions',\n",
              " 'fundamental',\n",
              " 'furthermore',\n",
              " 'fusion',\n",
              " 'future',\n",
              " 'gain',\n",
              " 'gains',\n",
              " 'galactic',\n",
              " 'galaxies',\n",
              " 'galaxy',\n",
              " 'game',\n",
              " 'games',\n",
              " 'gaussian',\n",
              " 'general',\n",
              " 'generalization',\n",
              " 'generalize',\n",
              " 'generalized',\n",
              " 'generalizes',\n",
              " 'generalizing',\n",
              " 'generally',\n",
              " 'generate',\n",
              " 'generated',\n",
              " 'generates',\n",
              " 'generating',\n",
              " 'generation',\n",
              " 'generative',\n",
              " 'generator',\n",
              " 'generic',\n",
              " 'geometric',\n",
              " 'geometry',\n",
              " 'given',\n",
              " 'gives',\n",
              " 'giving',\n",
              " 'global',\n",
              " 'globally',\n",
              " 'goal',\n",
              " 'good',\n",
              " 'gradient',\n",
              " 'gradients',\n",
              " 'graph',\n",
              " 'graphical',\n",
              " 'graphs',\n",
              " 'gravitational',\n",
              " 'gravity',\n",
              " 'great',\n",
              " 'greater',\n",
              " 'greatly',\n",
              " 'grid',\n",
              " 'ground',\n",
              " 'group',\n",
              " 'groups',\n",
              " 'growing',\n",
              " 'grows',\n",
              " 'growth',\n",
              " 'guarantee',\n",
              " 'guaranteed',\n",
              " 'guarantees',\n",
              " 'guide',\n",
              " 'half',\n",
              " 'hall',\n",
              " 'hamiltonian',\n",
              " 'hand',\n",
              " 'handle',\n",
              " 'handling',\n",
              " 'hard',\n",
              " 'hardware',\n",
              " 'harmonic',\n",
              " 'having',\n",
              " 'health',\n",
              " 'heat',\n",
              " 'heavy',\n",
              " 'help',\n",
              " 'helps',\n",
              " 'heterogeneous',\n",
              " 'heuristic',\n",
              " 'hidden',\n",
              " 'hierarchical',\n",
              " 'hierarchy',\n",
              " 'high',\n",
              " 'high-dimensional',\n",
              " 'high-resolution',\n",
              " 'higher',\n",
              " 'highest',\n",
              " 'highlight',\n",
              " 'highly',\n",
              " 'hilbert',\n",
              " 'history',\n",
              " 'hold',\n",
              " 'holds',\n",
              " 'hole',\n",
              " 'homogeneous',\n",
              " 'horizon',\n",
              " 'host',\n",
              " 'https',\n",
              " 'huge',\n",
              " 'human',\n",
              " 'humans',\n",
              " 'hybrid',\n",
              " 'hyperbolic',\n",
              " 'hypothesis',\n",
              " 'i.e.',\n",
              " 'idea',\n",
              " 'ideal',\n",
              " 'ideas',\n",
              " 'identical',\n",
              " 'identification',\n",
              " 'identified',\n",
              " 'identify',\n",
              " 'identifying',\n",
              " 'identity',\n",
              " 'illustrate',\n",
              " 'illustrated',\n",
              " 'image',\n",
              " 'images',\n",
              " 'imaging',\n",
              " 'impact',\n",
              " 'implement',\n",
              " 'implementation',\n",
              " 'implementations',\n",
              " 'implemented',\n",
              " 'implementing',\n",
              " 'implications',\n",
              " 'implicit',\n",
              " 'implies',\n",
              " 'imply',\n",
              " 'importance',\n",
              " 'important',\n",
              " 'importantly',\n",
              " 'improve',\n",
              " 'improved',\n",
              " 'improvement',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DNr9Cc7oVMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda = decomposition.LatentDirichletAllocation(n_components=6,max_iter=3,learning_method='online',learning_offset=100,n_jobs=1,random_state=111)\n",
        "\n",
        "W1 = lda.fit_transform(tf_vectors)\n",
        "H1 = lda.components_ "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FycGZFW5ptGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "5a546dbf-9c41-4135-aa1c-25f4ddaa4797"
      },
      "source": [
        "W1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.94812584, 0.03544061, 0.00410182, 0.00410342, 0.00411726,\n",
              "        0.00411105],\n",
              "       [0.00371892, 0.00374564, 0.94753396, 0.00372048, 0.03753446,\n",
              "        0.00374653],\n",
              "       [0.35441277, 0.19156994, 0.44447078, 0.00317804, 0.00315817,\n",
              "        0.0032103 ],\n",
              "       ...,\n",
              "       [0.14568127, 0.29792947, 0.04554584, 0.50174793, 0.00454774,\n",
              "        0.00454775],\n",
              "       [0.35077472, 0.22034925, 0.02014841, 0.40442467, 0.00215826,\n",
              "        0.00214468],\n",
              "       [0.30384167, 0.21938899, 0.01193502, 0.01190782, 0.01195389,\n",
              "        0.44097261]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6HvVICXpuon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = 20\n",
        "\n",
        "vocab = np.array(vectorizer_tf.get_feature_names())\n",
        "\n",
        "top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_words-1:-1]]\n",
        "topic_words = ([top_words(t) for t in H1])\n",
        "topics = [' '.join(t) for t in topic_words]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97rJJLegqnVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "f0e8d19b-63f8-4615-8c60-7a65ba59e72e"
      },
      "source": [
        "topics"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['problem algorithm method model time paper optimal function number proposed algorithms random problems results linear methods optimization based graph models',\n",
              " 'learning network networks model data neural approach using deep models training paper performance based features propose information proposed different methods',\n",
              " 'model results mass using time models dynamics flow data different present observations simulations rate study high analysis observed dark formation',\n",
              " 'data paper using results information learning research methods model method used analysis study based proposed control knowledge performance real studies',\n",
              " 'energy quantum phase magnetic field state states model spin transition theory temperature surface using study order systems properties wave density',\n",
              " 'prove \\\\mathbb space group paper \\\\mathcal results finite result study groups theory case number functions given theorem function spaces class']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZMojnQKqozx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colnames = [\"Topic\" + str(i) for i in range(lda.n_components)]\n",
        "docnames = [\"Doc\" + str(i) for i in range(len(X_train.ABSTRACT))]\n",
        "\n",
        "df_doc_topic = pd.DataFrame(np.round(W1,2),columns=colnames,index=docnames)\n",
        "significanttopic = np.argmax(df_doc_topic.values,axis=1)\n",
        "\n",
        "df_doc_topic['dominant_topic'] = significanttopic"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upHoOP3Tr-mU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "b334b859-7961-44fd-d719-7ff21d0d50e2"
      },
      "source": [
        "df_doc_topic"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic0</th>\n",
              "      <th>Topic1</th>\n",
              "      <th>Topic2</th>\n",
              "      <th>Topic3</th>\n",
              "      <th>Topic4</th>\n",
              "      <th>Topic5</th>\n",
              "      <th>dominant_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Doc0</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc1</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc2</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.24</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc8984</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc8985</th>\n",
              "      <td>0.90</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc8986</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc8987</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc8988</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.44</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8989 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Topic0  Topic1  Topic2  Topic3  Topic4  Topic5  dominant_topic\n",
              "Doc0     0.95    0.04    0.00    0.00    0.00    0.00    0             \n",
              "Doc1     0.00    0.00    0.95    0.00    0.04    0.00    2             \n",
              "Doc2     0.35    0.19    0.44    0.00    0.00    0.00    2             \n",
              "Doc3     0.00    0.00    0.99    0.00    0.00    0.00    2             \n",
              "Doc4     0.00    0.00    0.00    0.64    0.10    0.24    3             \n",
              "...       ...     ...     ...     ...     ...     ...   ..             \n",
              "Doc8984  0.55    0.44    0.00    0.00    0.00    0.00    0             \n",
              "Doc8985  0.90    0.01    0.01    0.01    0.07    0.01    0             \n",
              "Doc8986  0.15    0.30    0.05    0.50    0.00    0.00    3             \n",
              "Doc8987  0.35    0.22    0.02    0.40    0.00    0.00    3             \n",
              "Doc8988  0.30    0.22    0.01    0.01    0.01    0.44    5             \n",
              "\n",
              "[8989 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3-5QqaUsArk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "dfece758-3963-46f6-d788-fc0bbce3e67d"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20973</td>\n",
              "      <td>Closed-form Marginal Likelihood in Gamma-Poisson Matrix Factorization</td>\n",
              "      <td>We present novel understandings of the Gamma-Poisson (GaP) model, a\\nprobabilistic matrix factorization model for count data. We show that GaP can\\nbe rewritten free of the score/activation matrix. This gives us new insights\\nabout the estimation of the topic/dictionary matrix by maximum marginal\\nlikelihood estimation. In particular, this explains the robustness of this\\nestimator to over-specified values of the factorization rank, especially its\\nability to automatically prune irrelevant dictionary columns, as empirically\\nobserved in previous work. The marginalization of the activation matrix leads\\nin turn to a new Monte Carlo Expectation-Maximization algorithm with favorable\\nproperties.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20974</td>\n",
              "      <td>Laboratory mid-IR spectra of equilibrated and igneous meteorites. Searching for observables of planetesimal debris</td>\n",
              "      <td>Meteorites contain minerals from Solar System asteroids with different\\nproperties (like size, presence of water, core formation). We provide new\\nmid-IR transmission spectra of powdered meteorites to obtain templates of how\\nmid-IR spectra of asteroidal debris would look like. This is essential for\\ninterpreting mid-IR spectra of past and future space observatories, like the\\nJames Webb Space Telescope. We show that the transmission spectra of wet and\\ndry chondrites, carbonaceous and ordinary chondrites and achondrite and\\nchondrite meteorites are distinctly different in a way one can distinguish in\\nastronomical mid-IR spectra. The two observables that spectroscopically\\nseparate the different meteorites groups (and thus the different types of\\nparent bodies) are the pyroxene-olivine feature strength ratio and the peak\\nshift of the olivine spectral features due to an increase in the iron\\nconcentration of the olivine.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20975</td>\n",
              "      <td>Case For Static AMSDU Aggregation in WLANs</td>\n",
              "      <td>Frame aggregation is a mechanism by which multiple frames are combined into a\\nsingle transmission unit over the air. Frames aggregated at the AMSDU level use\\na common CRC check to enforce integrity. For longer aggregated AMSDU frames,\\nthe packet error rate increases significantly for the same bit error rate.\\nHence, multiple studies have proposed doing AMSDU aggregation adaptively based\\non the error rate. This study evaluates if there is a \\emph{practical}\\nadvantage in doing adaptive AMSDU aggregation based on the link bit error rate.\\nEvaluations on a model show that instead of implementing a complex adaptive\\nAMSDU frame aggregation mechanism which impact queuing and other implementation\\naspects, it is easier to influence packet error rate with traditional\\nmechanisms while keeping the AMSDU aggregation logic simple.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20976</td>\n",
              "      <td>The $Gaia$-ESO Survey: the inner disk intermediate-age open cluster NGC 6802</td>\n",
              "      <td>Milky Way open clusters are very diverse in terms of age, chemical\\ncomposition, and kinematic properties. Intermediate-age and old open clusters\\nare less common, and it is even harder to find them inside the solar\\nGalactocentric radius, due to the high mortality rate and strong extinction\\ninside this region. NGC 6802 is one of the inner disk open clusters (IOCs)\\nobserved by the $Gaia$-ESO survey (GES). This cluster is an important target\\nfor calibrating the abundances derived in the survey due to the kinematic and\\nchemical homogeneity of the members in open clusters. Using the measurements\\nfrom $Gaia$-ESO internal data release 4 (iDR4), we identify 95 main-sequence\\ndwarfs as cluster members from the GIRAFFE target list, and eight giants as\\ncluster members from the UVES target list. The dwarf cluster members have a\\nmedian radial velocity of $13.6\\pm1.9$ km s$^{-1}$, while the giant cluster\\nmembers have a median radial velocity of $12.0\\pm0.9$ km s$^{-1}$ and a median\\n[Fe/H] of $0.10\\pm0.02$ dex. The color-magnitude diagram of these cluster\\nmembers suggests an age of $0.9\\pm0.1$ Gyr, with $(m-M)_0=11.4$ and\\n$E(B-V)=0.86$. We perform the first detailed chemical abundance analysis of NGC\\n6802, including 27 elemental species. To gain a more general picture about\\nIOCs, the measurements of NGC 6802 are compared with those of other IOCs\\npreviously studied by GES, that is, NGC 4815, Trumpler 20, NGC 6705, and\\nBerkeley 81. NGC 6802 shows similar C, N, Na, and Al abundances as other IOCs.\\nThese elements are compared with nucleosynthetic models as a function of\\ncluster turn-off mass. The $\\alpha$, iron-peak, and neutron-capture elements\\nare also explored in a self-consistent way.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20977</td>\n",
              "      <td>Witness-Functions versus Interpretation-Functions for Secrecy in Cryptographic Protocols: What to Choose?</td>\n",
              "      <td>Proving that a cryptographic protocol is correct for secrecy is a hard task.\\nOne of the strongest strategies to reach this goal is to show that it is\\nincreasing, which means that the security level of every single atomic message\\nexchanged in the protocol, safely evaluated, never deceases. Recently, two\\nfamilies of functions have been proposed to measure the security level of\\natomic messages. The first one is the family of interpretation-functions. The\\nsecond is the family of witness-functions. In this paper, we show that the\\nwitness-functions are more efficient than interpretation-functions. We give a\\ndetailed analysis of an ad-hoc protocol on which the witness-functions succeed\\nin proving its correctness for secrecy while the interpretation-functions fail\\nto do so.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ID  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ABSTRACT\n",
              "0  20973  ...    We present novel understandings of the Gamma-Poisson (GaP) model, a\\nprobabilistic matrix factorization model for count data. We show that GaP can\\nbe rewritten free of the score/activation matrix. This gives us new insights\\nabout the estimation of the topic/dictionary matrix by maximum marginal\\nlikelihood estimation. In particular, this explains the robustness of this\\nestimator to over-specified values of the factorization rank, especially its\\nability to automatically prune irrelevant dictionary columns, as empirically\\nobserved in previous work. The marginalization of the activation matrix leads\\nin turn to a new Monte Carlo Expectation-Maximization algorithm with favorable\\nproperties.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
              "1  20974  ...    Meteorites contain minerals from Solar System asteroids with different\\nproperties (like size, presence of water, core formation). We provide new\\nmid-IR transmission spectra of powdered meteorites to obtain templates of how\\nmid-IR spectra of asteroidal debris would look like. This is essential for\\ninterpreting mid-IR spectra of past and future space observatories, like the\\nJames Webb Space Telescope. We show that the transmission spectra of wet and\\ndry chondrites, carbonaceous and ordinary chondrites and achondrite and\\nchondrite meteorites are distinctly different in a way one can distinguish in\\nastronomical mid-IR spectra. The two observables that spectroscopically\\nseparate the different meteorites groups (and thus the different types of\\nparent bodies) are the pyroxene-olivine feature strength ratio and the peak\\nshift of the olivine spectral features due to an increase in the iron\\nconcentration of the olivine.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "2  20975  ...    Frame aggregation is a mechanism by which multiple frames are combined into a\\nsingle transmission unit over the air. Frames aggregated at the AMSDU level use\\na common CRC check to enforce integrity. For longer aggregated AMSDU frames,\\nthe packet error rate increases significantly for the same bit error rate.\\nHence, multiple studies have proposed doing AMSDU aggregation adaptively based\\non the error rate. This study evaluates if there is a \\emph{practical}\\nadvantage in doing adaptive AMSDU aggregation based on the link bit error rate.\\nEvaluations on a model show that instead of implementing a complex adaptive\\nAMSDU frame aggregation mechanism which impact queuing and other implementation\\naspects, it is easier to influence packet error rate with traditional\\nmechanisms while keeping the AMSDU aggregation logic simple.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
              "3  20976  ...    Milky Way open clusters are very diverse in terms of age, chemical\\ncomposition, and kinematic properties. Intermediate-age and old open clusters\\nare less common, and it is even harder to find them inside the solar\\nGalactocentric radius, due to the high mortality rate and strong extinction\\ninside this region. NGC 6802 is one of the inner disk open clusters (IOCs)\\nobserved by the $Gaia$-ESO survey (GES). This cluster is an important target\\nfor calibrating the abundances derived in the survey due to the kinematic and\\nchemical homogeneity of the members in open clusters. Using the measurements\\nfrom $Gaia$-ESO internal data release 4 (iDR4), we identify 95 main-sequence\\ndwarfs as cluster members from the GIRAFFE target list, and eight giants as\\ncluster members from the UVES target list. The dwarf cluster members have a\\nmedian radial velocity of $13.6\\pm1.9$ km s$^{-1}$, while the giant cluster\\nmembers have a median radial velocity of $12.0\\pm0.9$ km s$^{-1}$ and a median\\n[Fe/H] of $0.10\\pm0.02$ dex. The color-magnitude diagram of these cluster\\nmembers suggests an age of $0.9\\pm0.1$ Gyr, with $(m-M)_0=11.4$ and\\n$E(B-V)=0.86$. We perform the first detailed chemical abundance analysis of NGC\\n6802, including 27 elemental species. To gain a more general picture about\\nIOCs, the measurements of NGC 6802 are compared with those of other IOCs\\npreviously studied by GES, that is, NGC 4815, Trumpler 20, NGC 6705, and\\nBerkeley 81. NGC 6802 shows similar C, N, Na, and Al abundances as other IOCs.\\nThese elements are compared with nucleosynthetic models as a function of\\ncluster turn-off mass. The $\\alpha$, iron-peak, and neutron-capture elements\\nare also explored in a self-consistent way.\\n\n",
              "4  20977  ...    Proving that a cryptographic protocol is correct for secrecy is a hard task.\\nOne of the strongest strategies to reach this goal is to show that it is\\nincreasing, which means that the security level of every single atomic message\\nexchanged in the protocol, safely evaluated, never deceases. Recently, two\\nfamilies of functions have been proposed to measure the security level of\\natomic messages. The first one is the family of interpretation-functions. The\\nsecond is the family of witness-functions. In this paper, we show that the\\nwitness-functions are more efficient than interpretation-functions. We give a\\ndetailed analysis of an ad-hoc protocol on which the witness-functions succeed\\nin proving its correctness for secrecy while the interpretation-functions fail\\nto do so.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSbb6z0rLys8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}